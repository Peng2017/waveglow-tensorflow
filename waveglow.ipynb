{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python import pywrap_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_from_checkpoint_file(file_name):\n",
    "    variables = []\n",
    "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
    "\n",
    "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "    for key in sorted(var_to_shape_map):\n",
    "        variables.append((key, var_to_shape_map[key]))\n",
    "\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10506\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import ntpath\n",
    "\n",
    "data_dir = '/home/scpark/ai/datasets/waveglow-datasets/jeon'\n",
    "data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) and '.npz' in f]\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_AXIS = 0\n",
    "TIME_AXIS = 1\n",
    "CHANNEL_AXIS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(inputs, filters, kernel_size=1, dilation_rate=1, zero_init=False, name='conv1d', reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        \n",
    "        x = inputs[:, None, :, :]\n",
    "        \n",
    "        V_initializer = tf.constant_initializer(0.) if zero_init else tf.random_normal_initializer(0, 0.05)\n",
    "        V = tf.get_variable('V', [1, kernel_size, int(inputs.get_shape()[-1]), filters], tf.float32, \n",
    "                            initializer=V_initializer, trainable=True)\n",
    "        g = tf.get_variable('g', [filters], dtype=tf.float32, initializer=tf.constant_initializer(1.), trainable=True)\n",
    "        b = tf.get_variable('b', [filters], dtype=tf.float32, initializer=tf.constant_initializer(0.), trainable=True)\n",
    "        \n",
    "        # use weight normalization (Salimans & Kingma, 2016)\n",
    "        W = tf.reshape(g, [1, 1, 1, filters]) * tf.nn.l2_normalize(V, [0, 1, 2])\n",
    "\n",
    "        # calculate convolutional layer output\n",
    "        x = tf.nn.bias_add(tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID', dilations=[1, 1, dilation_rate, 1]), b)\n",
    "        x = x[:, 0, :, :]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.framework.python.ops import add_arg_scope\n",
    "\n",
    "# Invertible 1x1 conv\n",
    "@add_arg_scope\n",
    "def invertible_1x1_conv(name, z, c, reverse=False):\n",
    "\n",
    "    if True:  # Set to \"False\" to use the LU-decomposed version\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "\n",
    "            shape = tf.shape(z)\n",
    "            w_shape = [c, c]\n",
    "\n",
    "            # Sample a random orthogonal matrix:\n",
    "            w_init = np.linalg.qr(np.random.randn(\n",
    "                *w_shape))[0].astype('float32')\n",
    "            \n",
    "            if np.linalg.det(w_init) < 0:\n",
    "                w_init[:, 0] = -1. * w_init[:, 0]\n",
    "\n",
    "            w = tf.get_variable(\"W\", dtype=tf.float32, initializer=w_init)\n",
    "\n",
    "            # dlogdet = tf.linalg.LinearOperator(w).log_abs_determinant() * shape[1]*shape[2]\n",
    "            dlogdet = tf.cast(tf.log(abs(tf.matrix_determinant(\n",
    "                tf.cast(w, 'float64')))), 'float32') * tf.cast(shape[0] * shape[1] * shape[2], tf.float32)\n",
    "\n",
    "            if not reverse:\n",
    "\n",
    "                _w = tf.reshape(w, [1, 1] + w_shape)\n",
    "                z = tf.nn.conv2d(z, _w, [1, 1, 1, 1],\n",
    "                                 'SAME', data_format='NHWC')\n",
    "\n",
    "                return z, dlogdet\n",
    "            else:\n",
    "\n",
    "                _w = tf.matrix_inverse(w)\n",
    "                _w = tf.reshape(_w, [1, 1]+w_shape)\n",
    "                z = tf.nn.conv2d(z, _w, [1, 1, 1, 1],\n",
    "                                 'SAME', data_format='NHWC')\n",
    "\n",
    "                return z, dlogdet\n",
    "\n",
    "            \n",
    "def Invertible1x1Conv(z, c, reverse=False, name='inv1x1conv', reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        z = z[:, None, :, :]\n",
    "        z, logdet = invertible_1x1_conv(name, z, c, reverse=reverse)\n",
    "        z = z[:, 0, :, :]\n",
    "        \n",
    "        if reverse:\n",
    "            return z\n",
    "        else:\n",
    "            return z, logdet    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fused_add_tanh_sigmoid_multiply(input_a, input_b, n_channels):\n",
    "    in_act = input_a + input_b\n",
    "    t_act = tf.tanh(in_act[:, :, :n_channels])\n",
    "    s_act = tf.sigmoid(in_act[:, :, n_channels:])\n",
    "    acts = t_act * s_act\n",
    "    \n",
    "    return acts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WN(audio, spect, n_channels, n_layers, kernel_size, name='wavenet', reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        n_in_channels = int(audio.get_shape()[-1])\n",
    "        \n",
    "        audio = conv1d(audio, n_channels, name='start')\n",
    "    \n",
    "        for i in range(n_layers):\n",
    "            \n",
    "            with tf.variable_scope(str(i), reuse=tf.AUTO_REUSE):\n",
    "                \n",
    "                dilation = 2 ** i\n",
    "                padding = int((kernel_size * dilation - dilation) / 2)\n",
    "                audio_padded = tf.pad(audio, [[0, 0], [padding, padding], [0, 0]])\n",
    "                \n",
    "                in_acts = conv1d(audio_padded, 2 * n_channels, kernel_size, dilation, name='in_layer')\n",
    "                cond_acts = conv1d(spect, 2 * n_channels, name='cond_layer')\n",
    "                acts = fused_add_tanh_sigmoid_multiply(in_acts, cond_acts, n_channels)\n",
    "                \n",
    "                res_skip_channels = 2 * n_channels if i < n_layers - 1 else n_channels\n",
    "                res_skip_acts = conv1d(acts, res_skip_channels, name='res_skip_layer')\n",
    "                \n",
    "                if i < n_layers - 1:\n",
    "                    audio = res_skip_acts[:, :, :n_channels] + audio\n",
    "                    skip_acts = res_skip_acts[:, :, n_channels:]\n",
    "                else:\n",
    "                    skip_acts = res_skip_acts\n",
    "                    \n",
    "                if i == 0:\n",
    "                    output = skip_acts\n",
    "                else:\n",
    "                    output = skip_acts + output\n",
    "\n",
    "        # Zero Initialization\n",
    "        # Glow : Generative Flow with Invertible 1x1 Convolutions\n",
    "        output = tf.layers.conv1d(output, filters=2 * n_in_channels,\n",
    "                                kernel_size=1, \n",
    "                                kernel_initializer=tf.zeros_initializer(), \n",
    "                                bias_initializer=tf.zeros_initializer(), reuse=reuse)\n",
    "        output_a, output_b = tf.split(output, num_or_size_splits=2, axis=CHANNEL_AXIS)\n",
    "        \n",
    "        return output_a, output_b\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(spect, n_mel_channels, kernel_size, stride, name='upsample', reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        # spect : [Batch, Time, n_mel_channels]\n",
    "        \n",
    "        # expand height\n",
    "        upsampled_spect = spect[:, None, :, :]\n",
    "        upsampled_spect = tf.layers.conv2d_transpose(inputs=upsampled_spect, \n",
    "                                                     filters=n_mel_channels, \n",
    "                                                     kernel_size=(1, kernel_size), \n",
    "                                                     strides=(1, stride),\n",
    "                                                     padding='SAME')\n",
    "        upsampled_spect = upsampled_spect[:, 0, :, :]\n",
    "    \n",
    "    return upsampled_spect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveGlow(audio, spect, n_mel_channels, n_flows, n_group, n_early_every, n_early_size, \n",
    "             WN_n_channels, WN_n_layers, WN_kernel_size,\n",
    "             name='WaveGlow', reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "    \n",
    "        # audio : [Batch, Time]\n",
    "        # spect : [Batch, Time / 256, n_mel_channels]\n",
    "\n",
    "        Batch = tf.shape(audio)[0]\n",
    "        Time = tf.shape(audio)[1]\n",
    "\n",
    "        # [Batch, Time, n_mel_channels]\n",
    "        spect = upsample(spect, n_mel_channels, 1024, 256)\n",
    "        #spect = spect[:, :Time]\n",
    "        \n",
    "        # [Batch, Time / n_group, n_mel_channels * n_group]\n",
    "        spect = tf.reshape(spect, [Batch, -1, n_mel_channels * n_group])\n",
    "        audio = tf.reshape(audio, [Batch, -1, n_group])\n",
    "\n",
    "        output_audio = []\n",
    "        log_s_list = []\n",
    "        log_det_W_list = []\n",
    "\n",
    "        n_remaining_channels = n_group\n",
    "\n",
    "        for k in range(n_flows):\n",
    "            \n",
    "            with tf.variable_scope('flow_' + str(k), reuse=reuse):\n",
    "                \n",
    "                print('flow ', k)\n",
    "                \n",
    "                if k % n_early_every == 0 and k > 0:\n",
    "                    output_audio.append(audio[:, :, :n_early_size])\n",
    "                    audio = audio[:, :, n_early_size:]\n",
    "                    n_remaining_channels = n_remaining_channels - n_early_size\n",
    "                    \n",
    "                audio, log_det_W = Invertible1x1Conv(audio, n_remaining_channels)\n",
    "                log_det_W_list.append(log_det_W)\n",
    "\n",
    "                audio_0, audio_1 = tf.split(audio, 2, axis=CHANNEL_AXIS)\n",
    "\n",
    "                log_s, b = WN(audio_0, spect, \n",
    "                            n_channels=WN_n_channels, n_layers=WN_n_layers, kernel_size=WN_kernel_size)\n",
    "\n",
    "                audio_1 = tf.exp(log_s) * audio_1 + b\n",
    "                log_s_list.append(log_s)\n",
    "\n",
    "                audio = tf.concat([audio_0, audio_1], axis=CHANNEL_AXIS)\n",
    "\n",
    "        output_audio.append(audio)\n",
    "\n",
    "        return tf.concat(output_audio, axis=CHANNEL_AXIS), log_s_list, log_det_W_list, n_remaining_channels\n",
    "    \n",
    "def waveGlowInverse(spect, n_mel_channels, n_flows, n_group, n_early_every, n_early_size, n_remaining_channels,\n",
    "                    WN_n_channels, WN_n_layers, WN_kernel_size,\n",
    "                    sigma=1.0, name='WaveGlow', reuse=True):\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        \n",
    "        # spect : [Batch, Time / 256, n_mel_channels]\n",
    "        \n",
    "        time_cutoff = 1024 - 256\n",
    "        spect = upsample(spect, n_mel_channels, 1024, 256, reuse=reuse)\n",
    "        #spect = spect[:, :-time_cutoff]\n",
    "        Batch = tf.shape(spect)[0]\n",
    "        \n",
    "        spect = tf.reshape(spect, [Batch, -1, n_mel_channels * n_group])\n",
    "        Time = tf.shape(spect)[1]\n",
    "\n",
    "        audio = tf.random_normal(shape=[Batch, Time, n_remaining_channels], stddev=sigma, dtype=tf.float32)\n",
    "        \n",
    "        for k in reversed(range(n_flows)):\n",
    "            \n",
    "            with tf.variable_scope('flow_' + str(k), reuse=reuse):\n",
    "                \n",
    "                print('inverse flow ', k)\n",
    "                \n",
    "                audio_0, audio_1 = tf.split(audio, 2, axis=CHANNEL_AXIS)\n",
    "                log_s, b = WN(audio_0, spect, \n",
    "                            n_channels=WN_n_channels, n_layers=WN_n_layers, kernel_size=WN_kernel_size)\n",
    "                audio_1 = (audio_1 - b) / tf.exp(log_s)\n",
    "                audio = tf.concat([audio_0, audio_1], axis=CHANNEL_AXIS)\n",
    "                \n",
    "                audio = Invertible1x1Conv(audio, n_remaining_channels, reverse=True)\n",
    "                \n",
    "                if k % n_early_every == 0 and k > 0:\n",
    "                    z = tf.random_normal(shape=[Batch, Time, n_early_size], dtype=tf.float32)\n",
    "                    audio = tf.concat([sigma * z, audio], axis=CHANNEL_AXIS)\n",
    "                    n_remaining_channels = n_remaining_channels + n_early_size\n",
    "        \n",
    "        audio = tf.reshape(audio, [Batch, -1])\n",
    "        \n",
    "        return audio\n",
    "    \n",
    "def waveGlowLoss(z, log_s_list, log_det_W_list, sigma=1.0):\n",
    "    \n",
    "    log_s_total = 0\n",
    "    log_det_W_total = 0\n",
    "    \n",
    "    for i, log_s in enumerate(log_s_list):\n",
    "        log_s_total += tf.reduce_sum(log_s)\n",
    "        log_det_W_total += log_det_W_list[i]\n",
    "        \n",
    "    nll_loss = tf.reduce_sum(z * z) / (2. * sigma * sigma) \n",
    "    det_loss = -log_s_total - log_det_W_total\n",
    "    norm_factor = tf.cast(tf.shape(z)[0] * tf.shape(z)[1] * tf.shape(z)[2], tf.float32)\n",
    "    loss = (nll_loss + det_loss) / norm_factor\n",
    "    \n",
    "    return nll_loss, det_loss, loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow  0\n",
      "flow  1\n",
      "flow  2\n",
      "flow  3\n",
      "flow  4\n",
      "flow  5\n",
      "flow  6\n",
      "flow  7\n",
      "flow  8\n",
      "flow  9\n",
      "flow  10\n",
      "flow  11\n",
      "Tensor(\"WaveGlow/concat:0\", shape=(?, ?, 8), dtype=float32)\n",
      "inverse flow  11\n",
      "inverse flow  10\n",
      "inverse flow  9\n",
      "inverse flow  8\n",
      "inverse flow  7\n",
      "inverse flow  6\n",
      "inverse flow  5\n",
      "inverse flow  4\n",
      "inverse flow  3\n",
      "inverse flow  2\n",
      "inverse flow  1\n",
      "inverse flow  0\n",
      "Tensor(\"WaveGlow_1/Reshape_1:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"truediv_1:0\", shape=(), dtype=float32)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "Batch = None\n",
    "Time = None\n",
    "n_mel_channels = 80\n",
    "n_flows = 12\n",
    "n_group = 8\n",
    "n_early_every = 4\n",
    "n_early_size = 2\n",
    "\n",
    "WN_n_layers = 8\n",
    "WN_n_channels = 512\n",
    "WN_kernel_size = 3\n",
    "\n",
    "audio = tf.placeholder(dtype=tf.float32, shape=[Batch, None])\n",
    "spect = tf.placeholder(dtype=tf.float32, shape=[Batch, None, n_mel_channels])\n",
    "\n",
    "z, log_s_list, log_det_W_list, n_remaining_channels = \\\n",
    "                    waveGlow(audio, spect, n_mel_channels, n_flows, n_group, n_early_every, n_early_size,\n",
    "                            WN_n_channels, WN_n_layers, WN_kernel_size)\n",
    "\n",
    "print(z)\n",
    "    \n",
    "audio_sample = waveGlowInverse(spect, n_mel_channels, n_flows, n_group, n_early_every, n_early_size, n_remaining_channels,\n",
    "                                 WN_n_channels, WN_n_layers, WN_kernel_size, reuse=True)\n",
    "print(audio_sample)\n",
    "\n",
    "nll_loss, det_loss, loss = waveGlowLoss(z, log_s_list, log_det_W_list, sigma=1.0)\n",
    "print(loss)\n",
    "\n",
    "optim = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(time_length, index):\n",
    "    waves = []\n",
    "    specs = []\n",
    "    \n",
    "    data_file = data_files[index]\n",
    "    data = np.load(data_file)\n",
    "    wave, spec = data['wave'], data['mel']\n",
    "\n",
    "    start = 0\n",
    "    end = time_length\n",
    "    waves = wave[start * 256 : end * 256]\n",
    "    specs = spec[start:end]\n",
    "    \n",
    "    return waves, specs\n",
    "    \n",
    "\n",
    "def get_data(time_length):\n",
    "    waves = []\n",
    "    specs = []\n",
    "    \n",
    "    while len(specs) < 3:\n",
    "        read_index = np.random.randint(0, len(data_files) - 1, 1)[0]\n",
    "        data_file = data_files[read_index]\n",
    "        data = np.load(data_file)\n",
    "        wave, spec = data['wave'], data['mel']\n",
    "\n",
    "        if len(spec) == 0 or len(wave) == 0:\n",
    "            continue\n",
    "\n",
    "        waves.append(wave)\n",
    "        specs.append(spec)\n",
    "\n",
    "    waves = np.concatenate(waves, axis=0)\n",
    "    specs = np.concatenate(specs, axis=0)\n",
    "\n",
    "    length = np.maximum(len(specs), time_length)\n",
    "    if length > time_length:\n",
    "        start = np.random.randint(length - time_length, size=1)[0]\n",
    "    else:\n",
    "        start = 0\n",
    "\n",
    "    end = start + time_length\n",
    "    waves = waves[start * 256 : end * 256]\n",
    "    specs = specs[start:end]\n",
    "    \n",
    "    return waves, specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12800,) (50, 80)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1,1602,1024] vs. [1,1600,1024]\n\t [[Node: WaveGlow/flow_0/wavenet/1/add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](WaveGlow/flow_0/wavenet/1/in_layer/strided_slice_1, WaveGlow/flow_0/wavenet/1/cond_layer/strided_slice_1)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_62210_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'WaveGlow/flow_0/wavenet/1/add', defined at:\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-97a74966d376>\", line 19, in <module>\n    WN_n_channels, WN_n_layers, WN_kernel_size)\n  File \"<ipython-input-20-ee9d4b668a49>\", line 44, in waveGlow\n    n_channels=WN_n_channels, n_layers=WN_n_layers, kernel_size=WN_kernel_size)\n  File \"<ipython-input-18-53b755ad7e0e>\", line 18, in WN\n    acts = fused_add_tanh_sigmoid_multiply(in_acts, cond_acts, n_channels)\n  File \"<ipython-input-17-2af00d23eb9c>\", line 2, in fused_add_tanh_sigmoid_multiply\n    in_act = input_a + input_b\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 297, in add\n    \"Add\", x=x, y=y, name=name)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,1602,1024] vs. [1,1600,1024]\n\t [[Node: WaveGlow/flow_0/wavenet/1/add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](WaveGlow/flow_0/wavenet/1/in_layer/strided_slice_1, WaveGlow/flow_0/wavenet/1/cond_layer/strided_slice_1)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_62210_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,1602,1024] vs. [1,1600,1024]\n\t [[Node: WaveGlow/flow_0/wavenet/1/add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](WaveGlow/flow_0/wavenet/1/in_layer/strided_slice_1, WaveGlow/flow_0/wavenet/1/cond_layer/strided_slice_1)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_62210_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4b734aa4b1a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         feed_dicts = {audio: np.expand_dims(waves, axis=0),\n\u001b[1;32m     14\u001b[0m                       spect: np.expand_dims(specs, axis=0)}\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_det_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_det_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,1602,1024] vs. [1,1600,1024]\n\t [[Node: WaveGlow/flow_0/wavenet/1/add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](WaveGlow/flow_0/wavenet/1/in_layer/strided_slice_1, WaveGlow/flow_0/wavenet/1/cond_layer/strided_slice_1)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_62210_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'WaveGlow/flow_0/wavenet/1/add', defined at:\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-97a74966d376>\", line 19, in <module>\n    WN_n_channels, WN_n_layers, WN_kernel_size)\n  File \"<ipython-input-20-ee9d4b668a49>\", line 44, in waveGlow\n    n_channels=WN_n_channels, n_layers=WN_n_layers, kernel_size=WN_kernel_size)\n  File \"<ipython-input-18-53b755ad7e0e>\", line 18, in WN\n    acts = fused_add_tanh_sigmoid_multiply(in_acts, cond_acts, n_channels)\n  File \"<ipython-input-17-2af00d23eb9c>\", line 2, in fused_add_tanh_sigmoid_multiply\n    in_act = input_a + input_b\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 297, in add\n    \"Add\", x=x, y=y, name=name)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,1602,1024] vs. [1,1600,1024]\n\t [[Node: WaveGlow/flow_0/wavenet/1/add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](WaveGlow/flow_0/wavenet/1/in_layer/strided_slice_1, WaveGlow/flow_0/wavenet/1/cond_layer/strided_slice_1)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_62210_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_length = 50\n",
    "\n",
    "while(True):\n",
    "    for i in range(100):\n",
    "        waves, specs = get_data(time_length)\n",
    "        print(waves.shape, specs.shape)\n",
    "        \n",
    "        fetches = [optim, loss, nll_loss, det_loss]\n",
    "        feed_dicts = {audio: np.expand_dims(waves, axis=0),\n",
    "                      spect: np.expand_dims(specs, axis=0)}\n",
    "        _, _loss, _nll_loss, _det_loss = sess.run(fetches, feed_dict=feed_dicts)\n",
    "        \n",
    "        print(_loss, _nll_loss, _det_loss)\n",
    "        \n",
    "    feed_dicts = {audio: np.expand_dims(waves, axis=0),\n",
    "                  spect: np.expand_dims(specs, axis=0)}\n",
    "    _audio_sample = sess.run(audio_sample, feed_dict=feed_dicts)\n",
    "    _audio_sample = np.clip(_audio_sample, -1., 1.)\n",
    "    clear_output()\n",
    "    \n",
    "    plt.figure(figsize=[18, 3])\n",
    "    plt.plot(waves, alpha=0.3)\n",
    "    plt.plot(_audio_sample[0], alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(_audio_sample[0], rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
